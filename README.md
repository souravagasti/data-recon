# DuckDB-Based Reconciliation Engine

## Overview
A lightweight, zero-cost data reconciliation engine built using Python and DuckDB.  
The solution is designed to compare large-scale datasets across cloud and on-premise sources with minimal resource usage, enabling high-speed reconciliation without the need for distributed compute.

---

## Key Features
- ğŸ” Supports multi-file, multi-source reconciliation (CSV, Excel, Parquet, Delta)
- âš™ï¸ Configurable through JSON mapping for primary keys and attribute comparisons
- ğŸš€ Fast, in-memory processing using DuckDB
- ğŸ“Š Generates comprehensive reconciliation reports in Excel (multi-sheet) format
- ğŸ’» Supports both local and cloud (Databricks) execution modes
- âœ… Handles schema drift, data type mismatches, and late-arriving records

---

## Project Structure
```text
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ duckdb_utils.py
â”‚   â”œâ”€â”€ reconciliation.py
â”‚   â”œâ”€â”€ databricks_utils.py
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ mapping.json
â”œâ”€â”€ sample_data/
â”œâ”€â”€ output/
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## Usage
1. Clone the repository:
```
git clone https://github.com/souravagasti/reconciliation-engine.git
```
2. Install dependencies:
```
pip install -r requirements.txt
```
3. Run the reconciliation:
```
python reconciliation.py --config src/config/mapping.json --platform local
```
For Databricks execution:
```python reconciliation.py --config src/config/mapping.json --platform databricks```
## Future Enhancements
âœ… Add unit tests and CI/CD integration

âœ… Build a user-friendly CLI

âœ… Add support for streaming reconciliation via Structured Streaming

âœ… Improve error handling and logging framework

âœ… Extend support for additional file types (JSON, Avro)

âœ… Add supportfor authentication via temporary credential vending for Unity Catalog-backed data

## Contact
For queries, improvements, or collaborations, feel free to reach out:
ğŸ“§ sourav.agasti@gmail.com
